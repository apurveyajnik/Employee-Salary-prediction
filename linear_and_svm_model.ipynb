{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_excel('train.xlsx',sheetname=0)\n",
    "test = pd.read_excel('test.xlsx',sheetname=0)\n",
    "(n,p) =train.shape\n",
    "(m,p)=test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5498, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert Gender into dummy columnes\n",
    "gen = pd.get_dummies(pd.concat([train['Gender'],test['Gender']],axis=0))\n",
    "b10 = pd.get_dummies(pd.concat([train['10board'],test['10board']],axis=0))\n",
    "deg = pd.get_dummies(pd.concat([train['Degree'],test['Degree']],axis=0))\n",
    "spec = pd.get_dummies(pd.concat([train['Specialization'],test['Specialization']],axis=0))\n",
    "gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop redundant and unused columns\n",
    "X = train.drop(['ID','Salary','DOJ','DOL','Designation','JobCity','Gender','DOB','10board','12board','Degree','Specialization','CollegeState','CollegeID','CollegeCityID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10percentage</th>\n",
       "      <th>12graduation</th>\n",
       "      <th>12percentage</th>\n",
       "      <th>CollegeTier</th>\n",
       "      <th>collegeGPA</th>\n",
       "      <th>CollegeCityTier</th>\n",
       "      <th>GraduationYear</th>\n",
       "      <th>English</th>\n",
       "      <th>Logical</th>\n",
       "      <th>Quant</th>\n",
       "      <th>Domain</th>\n",
       "      <th>ComputerProgramming</th>\n",
       "      <th>ElectronicsAndSemicon</th>\n",
       "      <th>ComputerScience</th>\n",
       "      <th>MechanicalEngg</th>\n",
       "      <th>ElectricalEngg</th>\n",
       "      <th>TelecomEngg</th>\n",
       "      <th>CivilEngg</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td> 84.3</td>\n",
       "      <td> 2007</td>\n",
       "      <td> 95.8</td>\n",
       "      <td> 2</td>\n",
       "      <td> 78.00</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2011</td>\n",
       "      <td> 515</td>\n",
       "      <td> 585</td>\n",
       "      <td> 525</td>\n",
       "      <td> 0.635979</td>\n",
       "      <td> 445</td>\n",
       "      <td>  -1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td> 0.9737</td>\n",
       "      <td> 0.8128</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td> 85.4</td>\n",
       "      <td> 2007</td>\n",
       "      <td> 85.0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 70.06</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2012</td>\n",
       "      <td> 695</td>\n",
       "      <td> 610</td>\n",
       "      <td> 780</td>\n",
       "      <td> 0.960603</td>\n",
       "      <td>  -1</td>\n",
       "      <td> 466</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.7335</td>\n",
       "      <td> 0.3789</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td> 85.0</td>\n",
       "      <td> 2010</td>\n",
       "      <td> 68.2</td>\n",
       "      <td> 2</td>\n",
       "      <td> 70.00</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2014</td>\n",
       "      <td> 615</td>\n",
       "      <td> 545</td>\n",
       "      <td> 370</td>\n",
       "      <td> 0.450877</td>\n",
       "      <td> 395</td>\n",
       "      <td>  -1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td> 0.2718</td>\n",
       "      <td> 1.7109</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td> 85.6</td>\n",
       "      <td> 2007</td>\n",
       "      <td> 83.6</td>\n",
       "      <td> 1</td>\n",
       "      <td> 74.64</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2011</td>\n",
       "      <td> 635</td>\n",
       "      <td> 585</td>\n",
       "      <td> 625</td>\n",
       "      <td> 0.974396</td>\n",
       "      <td> 615</td>\n",
       "      <td>  -1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td> 0.0464</td>\n",
       "      <td> 0.3448</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td> 78.0</td>\n",
       "      <td> 2008</td>\n",
       "      <td> 76.8</td>\n",
       "      <td> 2</td>\n",
       "      <td> 73.90</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2012</td>\n",
       "      <td> 545</td>\n",
       "      <td> 625</td>\n",
       "      <td> 465</td>\n",
       "      <td> 0.124502</td>\n",
       "      <td>  -1</td>\n",
       "      <td> 233</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.8810</td>\n",
       "      <td>-0.2793</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       10percentage  12graduation  12percentage  CollegeTier  collegeGPA  \\\n",
       "train          84.3          2007          95.8            2       78.00   \n",
       "train          85.4          2007          85.0            2       70.06   \n",
       "train          85.0          2010          68.2            2       70.00   \n",
       "train          85.6          2007          83.6            1       74.64   \n",
       "train          78.0          2008          76.8            2       73.90   \n",
       "\n",
       "       CollegeCityTier  GraduationYear  English  Logical  Quant    Domain  \\\n",
       "train                0            2011      515      585    525  0.635979   \n",
       "train                0            2012      695      610    780  0.960603   \n",
       "train                0            2014      615      545    370  0.450877   \n",
       "train                1            2011      635      585    625  0.974396   \n",
       "train                0            2012      545      625    465  0.124502   \n",
       "\n",
       "       ComputerProgramming  ElectronicsAndSemicon  ComputerScience  \\\n",
       "train                  445                     -1               -1   \n",
       "train                   -1                    466               -1   \n",
       "train                  395                     -1               -1   \n",
       "train                  615                     -1               -1   \n",
       "train                   -1                    233               -1   \n",
       "\n",
       "       MechanicalEngg  ElectricalEngg  TelecomEngg  CivilEngg  \\\n",
       "train              -1              -1           -1         -1   \n",
       "train              -1              -1           -1         -1   \n",
       "train              -1              -1           -1         -1   \n",
       "train              -1              -1           -1         -1   \n",
       "train              -1              -1           -1         -1   \n",
       "\n",
       "       conscientiousness  agreeableness      \n",
       "train             0.9737         0.8128 ...  \n",
       "train            -0.7335         0.3789 ...  \n",
       "train             0.2718         1.7109 ...  \n",
       "train             0.0464         0.3448 ...  \n",
       "train            -0.8810        -0.2793 ...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "X.ComputerProgramming = preprocessing.scale(train['ComputerProgramming'].replace(-1,None))\n",
    "X.ElectronicsAndSemicon = preprocessing.scale(train['ElectronicsAndSemicon'].replace(-1,None))\n",
    "X.ComputerScience = preprocessing.scale(train['ComputerScience'].replace(-1,None))\n",
    "X.MechanicalEngg = preprocessing.scale(train['MechanicalEngg'].replace(-1,None))\n",
    "X.ElectricalEngg = preprocessing.scale(train['ElectricalEngg'].replace(-1,None))\n",
    "X.TelecomEngg = preprocessing.scale(train['TelecomEngg'].replace(-1,None))\n",
    "X.CivilEngg = preprocessing.scale(train['CivilEngg'].replace(-1,None))\n",
    "max_scale =X[['ComputerProgramming','ElectronicsAndSemicon','ComputerScience','MechanicalEngg','ElectricalEngg','TelecomEngg','CivilEngg']].max(axis=1)\n",
    "X.Domain = X.Domain.replace(-1,max_scale)\n",
    "\n",
    "X = X.drop(['ComputerProgramming','ElectronicsAndSemicon','ComputerScience','MechanicalEngg','ElectricalEngg','TelecomEngg','CivilEngg'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10percentage</th>\n",
       "      <th>12graduation</th>\n",
       "      <th>12percentage</th>\n",
       "      <th>CollegeTier</th>\n",
       "      <th>collegeGPA</th>\n",
       "      <th>CollegeCityTier</th>\n",
       "      <th>GraduationYear</th>\n",
       "      <th>English</th>\n",
       "      <th>Logical</th>\n",
       "      <th>Quant</th>\n",
       "      <th>Domain</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>nueroticism</th>\n",
       "      <th>openess_to_experience</th>\n",
       "      <th>f</th>\n",
       "      <th>m</th>\n",
       "      <th>0</th>\n",
       "      <th> board of secondary education</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td> 84.3</td>\n",
       "      <td> 2007</td>\n",
       "      <td> 95.8</td>\n",
       "      <td> 2</td>\n",
       "      <td> 78.00</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2011</td>\n",
       "      <td> 515</td>\n",
       "      <td> 585</td>\n",
       "      <td> 525</td>\n",
       "      <td> 0.635979</td>\n",
       "      <td> 0.9737</td>\n",
       "      <td> 0.8128</td>\n",
       "      <td> 0.5269</td>\n",
       "      <td> 1.35490</td>\n",
       "      <td>-0.4455</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td> 85.4</td>\n",
       "      <td> 2007</td>\n",
       "      <td> 85.0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 70.06</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2012</td>\n",
       "      <td> 695</td>\n",
       "      <td> 610</td>\n",
       "      <td> 780</td>\n",
       "      <td> 0.960603</td>\n",
       "      <td>-0.7335</td>\n",
       "      <td> 0.3789</td>\n",
       "      <td> 1.2396</td>\n",
       "      <td>-0.10760</td>\n",
       "      <td> 0.8637</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td> 85.0</td>\n",
       "      <td> 2010</td>\n",
       "      <td> 68.2</td>\n",
       "      <td> 2</td>\n",
       "      <td> 70.00</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2014</td>\n",
       "      <td> 615</td>\n",
       "      <td> 545</td>\n",
       "      <td> 370</td>\n",
       "      <td> 0.450877</td>\n",
       "      <td> 0.2718</td>\n",
       "      <td> 1.7109</td>\n",
       "      <td> 0.1637</td>\n",
       "      <td>-0.86820</td>\n",
       "      <td> 0.6721</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td> 85.6</td>\n",
       "      <td> 2007</td>\n",
       "      <td> 83.6</td>\n",
       "      <td> 1</td>\n",
       "      <td> 74.64</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2011</td>\n",
       "      <td> 635</td>\n",
       "      <td> 585</td>\n",
       "      <td> 625</td>\n",
       "      <td> 0.974396</td>\n",
       "      <td> 0.0464</td>\n",
       "      <td> 0.3448</td>\n",
       "      <td>-0.3440</td>\n",
       "      <td>-0.40780</td>\n",
       "      <td>-0.9194</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td> 78.0</td>\n",
       "      <td> 2008</td>\n",
       "      <td> 76.8</td>\n",
       "      <td> 2</td>\n",
       "      <td> 73.90</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2012</td>\n",
       "      <td> 545</td>\n",
       "      <td> 625</td>\n",
       "      <td> 465</td>\n",
       "      <td> 0.124502</td>\n",
       "      <td>-0.8810</td>\n",
       "      <td>-0.2793</td>\n",
       "      <td>-1.0697</td>\n",
       "      <td> 0.09163</td>\n",
       "      <td>-0.1295</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 429 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       10percentage  12graduation  12percentage  CollegeTier  collegeGPA  \\\n",
       "train          84.3          2007          95.8            2       78.00   \n",
       "train          85.4          2007          85.0            2       70.06   \n",
       "train          85.0          2010          68.2            2       70.00   \n",
       "train          85.6          2007          83.6            1       74.64   \n",
       "train          78.0          2008          76.8            2       73.90   \n",
       "\n",
       "       CollegeCityTier  GraduationYear  English  Logical  Quant    Domain  \\\n",
       "train                0            2011      515      585    525  0.635979   \n",
       "train                0            2012      695      610    780  0.960603   \n",
       "train                0            2014      615      545    370  0.450877   \n",
       "train                1            2011      635      585    625  0.974396   \n",
       "train                0            2012      545      625    465  0.124502   \n",
       "\n",
       "       conscientiousness  agreeableness  extraversion  nueroticism  \\\n",
       "train             0.9737         0.8128        0.5269      1.35490   \n",
       "train            -0.7335         0.3789        1.2396     -0.10760   \n",
       "train             0.2718         1.7109        0.1637     -0.86820   \n",
       "train             0.0464         0.3448       -0.3440     -0.40780   \n",
       "train            -0.8810        -0.2793       -1.0697      0.09163   \n",
       "\n",
       "       openess_to_experience  f  m  0   board of secondary education      \n",
       "train                -0.4455  1  0  0                              0 ...  \n",
       "train                 0.8637  0  1  0                              0 ...  \n",
       "train                 0.6721  1  0  0                              0 ...  \n",
       "train                -0.9194  0  1  0                              0 ...  \n",
       "train                -0.1295  0  1  0                              0 ...  \n",
       "\n",
       "[5 rows x 429 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X,gen[:n],b10[:n],deg[:n],spec[:n]],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "Xs = X._get_numeric_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training for 3200 rows\n",
    "X_train = Xs[:3200]\n",
    "y_train = train[:3200].Salary\n",
    "\n",
    "clf_partial = LinearRegression()\n",
    "clf_partial = clf_partial.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162036.60222446467\n",
      "0.150492074542\n"
     ]
    }
   ],
   "source": [
    "#testing for rest of the rows\n",
    "X_test = Xs[3201:]\n",
    "y_test = train[3201:].Salary\n",
    "\n",
    "r_sqr = clf_partial.score(X_test,y_test)\n",
    "y_pred = clf_partial.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(rmse)\n",
    "print(r_sqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training for the full training set\n",
    "Xtrain = Xs\n",
    "ytrain = train.Salary\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf = clf.fit(Xtrain,ytrain)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test = pd.read_excel('test.xlsx',sheetname=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1500, 429)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing on the test file\n",
    "Xt = test.drop(['ID','Salary','DOJ','DOL','Designation','JobCity','Gender','DOB','10board','12board','Degree','Specialization','CollegeState','CollegeID','CollegeCityID'],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "Xt.ComputerProgramming = preprocessing.scale(test['ComputerProgramming'].replace(-1,None))\n",
    "Xt.ElectronicsAndSemicon = preprocessing.scale(test['ElectronicsAndSemicon'].replace(-1,None))\n",
    "Xt.ComputerScience = preprocessing.scale(test['ComputerScience'].replace(-1,None))\n",
    "Xt.MechanicalEngg = preprocessing.scale(test['MechanicalEngg'].replace(-1,None))\n",
    "Xt.ElectricalEngg = preprocessing.scale(test['ElectricalEngg'].replace(-1,None))\n",
    "Xt.TelecomEngg = preprocessing.scale(test['TelecomEngg'].replace(-1,None))\n",
    "Xt.CivilEngg = preprocessing.scale(test['CivilEngg'].replace(-1,None))\n",
    "\n",
    "max_scale =Xt[['ComputerProgramming','ElectronicsAndSemicon','ComputerScience','MechanicalEngg','ElectricalEngg','TelecomEngg','CivilEngg']].max(axis=1)\n",
    "\n",
    "Xt.Domain = Xt.Domain.replace(-1,max_scale)\n",
    "\n",
    "Xt = Xt.drop(['ComputerProgramming','ElectronicsAndSemicon','ComputerScience','MechanicalEngg','ElectricalEngg','TelecomEngg','CivilEngg'],axis=1)\n",
    "\n",
    "Xt = pd.concat([Xt,gen[n:],b10[n:],deg[n:],spec[n:]],axis=1)\n",
    "Xt = Xt._get_numeric_data()\n",
    "Xt.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#no Salaries in test set to compare to \n",
    "Xtest = Xt\n",
    "ytest = test.Salary\n",
    "\n",
    "#r_sqr = clf.score(Xtest,ytest)\n",
    "ypred = clf.predict(Xtest)\n",
    "\n",
    "#mae = mean_absolute_error(ytest,ypred)\n",
    "#rmse = sqrt(mean_squared_error(ytest, ypred))\n",
    "#print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# linear regression predictions saved in result1\n",
    "pd.DataFrame({'ID':test.ID,'Salary':ypred}).to_excel('result1.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using svm model\n",
    "sv= svm.SVR(kernel='linear')\n",
    "sal_pred = Pipeline([(\"feat_sel\",SelectKBest(k=400)),(\"svr\",sv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214073.82905720675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [ 19  20  22  23  25  27  29  30  32  33  39  42  43  46  52  53  58  60\n",
      "  68  70  78  79  82  88  92  95  96 100 102 104 105 106 107 110 112 116\n",
      " 118 122 133 138 140 141 142 146 148 149 152 158 166 170 172 173 179 180\n",
      " 182 183 184 186 189 194 198 203 205 209 213 216 217 218 220 230 231 232\n",
      " 239 241 245 252 254 257 260 261 262 266 268 272 275 276 279 284 288 289\n",
      " 291 294 295 297 298 300 304 305 306 312 313 314 318 325 326 330 335 338\n",
      " 342 345 347 348 353 355 359 360 361 364 365 374 377 379 383 388 391 395\n",
      " 404 408 421 425 427 428] are constant.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#training for 3200 rows via svm pipeline\n",
    "sal_pred.fit(X_train,y_train)\n",
    "y_tpred = sal_pred.predict(X_train)\n",
    "rmse = sqrt(mean_squared_error(y_train, y_tpred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169667.2937931462\n",
      "0.0685974018163\n"
     ]
    }
   ],
   "source": [
    "# this test set is part of the training file\n",
    "r_sqr = sal_pred.score(X_test,y_test)\n",
    "y_ppred = sal_pred.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test,y_ppred)\n",
    "rmse = sqrt(mean_squared_error(y_test, y_ppred))\n",
    "print(rmse)\n",
    "print(r_sqr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205842.54702164244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [ 19  20  22  23  25  27  33  53  58  60  68  78  88  95 100 102 105 106\n",
      " 112 116 118 122 138 141 142 146 149 152 158 166 170 173 180 183 184 186\n",
      " 189 198 203 205 216 220 230 231 232 239 245 252 257 260 261 266 276 279\n",
      " 284 289 291 295 297 298 300 305 306 312 313 314 318 325 326 330 335 338\n",
      " 348 353 355 360 361 365 374 379 383 391 404 408 421 425 427 428] are constant.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# train the full train dataset\n",
    "Xtrain = Xs\n",
    "ytrain = train.Salary\n",
    "sal_pred.fit(Xtrain,ytrain)\n",
    "y_tpred = sal_pred.predict(Xtrain)\n",
    "rmse = sqrt(mean_squared_error(ytrain, y_tpred))\n",
    "print(rmse)\n",
    "#printing the training rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#no Salaries in test set to compare to \n",
    "Xtest = Xt\n",
    "ytest = test.Salary\n",
    "\n",
    "#r_sqr = clf.score(Xtest,ytest)\n",
    "ypred = sal_pred.predict(Xtest)\n",
    "\n",
    "#mae = mean_absolute_error(ytest,ypred)\n",
    "#rmse = sqrt(mean_squared_error(ytest, ypred))\n",
    "#print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# svm predictions saved in result2\n",
    "pd.DataFrame({'ID':test.ID,'Salary':ypred}).to_excel('result2.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213930.6968870148\n"
     ]
    }
   ],
   "source": [
    "#training for 3200 rows via lasso\n",
    "las = linear_model.Ridge(alpha = 0.5)\n",
    "las.fit(X_train,y_train)\n",
    "y_tpred = sal_pred.predict(X_train)\n",
    "rmse = sqrt(mean_squared_error(y_train, y_tpred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160154.99619743132\n",
      "0.170106883666\n"
     ]
    }
   ],
   "source": [
    "# this test set is part of the training file\n",
    "r_sqr = las.score(X_test,y_test)\n",
    "y_lpred = las.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test,y_lpred)\n",
    "rmse = sqrt(mean_squared_error(y_test, y_lpred))\n",
    "print(rmse)\n",
    "print(r_sqr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
